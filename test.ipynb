{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'muxit (Python 3.11.10)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from audiocraft.models import MusicGen\n",
    "# from audiocraft.data.audio import audio_write\n",
    "\n",
    "# model = MusicGen.get_pretrained(\"facebook/musicgen-stereo-large\")\n",
    "# model.set_generation_params(duration=180)  # generate 8 seconds.\n",
    "\n",
    "# descriptions = [\n",
    "#     \"sad but pretend to be happy pop track with lyrics\",\n",
    "#     # \"happy electro pop track with lyrics\",\n",
    "# ]\n",
    "\n",
    "# wav = model.generate(descriptions)  # generates 2 samples.\n",
    "\n",
    "# for idx, one_wav in enumerate(wav):\n",
    "#     # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
    "#     audio_write(f'{idx}', one_wav.cpu(), model.sample_rate, strategy=\"loudness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 01:58:18.491743: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 01:58:21.027556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 01:58:29.238575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac4bf9f9344865b05a5c301511d3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "state_dict.bin:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /home/cachedir/cache/tmtong/torch/hub/checkpoints/955717e8-8726e21a.th\n",
      "100%|██████████| 80.2M/80.2M [00:01<00:00, 45.8MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0944196bc91e4d2694d77f6a754a4e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bd2bf0f5b247d0938e4df9a6687440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233f0efe51c34bf58f906ee206c9b156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cd0fce4c7e4395b025b8098d9bff0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8abe6c515b341b7bcdf768db4737f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "compression_state_dict.bin:   0%|          | 0.00/589 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262f5f62c8024cb29e75e71d1a7e5667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbf314c6ff24fb293ec20d8faef3c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/236M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/fyp24_ho3/tmtong/miniconda3/envs/muxit/lib/python3.11/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "model = MusicGen.get_pretrained(\"facebook/musicgen-stereo-melody-large\")\n",
    "model.set_generation_params(duration=200)  # generate 8 seconds.\n",
    "\n",
    "descriptions = ['happy rock', 'energetic EDM', 'sad jazz']\n",
    "\n",
    "melody, sr = torchaudio.load('./assets/bach.mp3')\n",
    "# generates using the melody from the given audio and the provided descriptions.\n",
    "wav = model.generate_with_chroma(descriptions, melody[None].expand(3, -1, -1), sr)\n",
    "\n",
    "for idx, one_wav in enumerate(wav):\n",
    "    # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
    "    audio_write(f'{idx}', one_wav.cpu(), model.sample_rate, strategy=\"loudness\")\n",
    "\n",
    "no_med_wav = model.generate(descriptions)  # generates without melody input.\n",
    "for idx, one_wav in enumerate(no_med_wav):\n",
    "    # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
    "    audio_write(f'{idx}_no_med', one_wav.cpu(), model.sample_rate, strategy=\"loudness\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ytid': '-0Gj8-vB1q4', 'start_s': 30, 'end_s': 40, 'audioset_positive_labels': '/m/0140xf,/m/02cjck,/m/04rlf', 'aspect_list': \"['low quality', 'sustained strings melody', 'soft female vocal', 'mellow piano melody', 'sad', 'soulful', 'ballad']\", 'caption': 'The low quality recording features a ballad song that contains sustained strings, mellow piano melody and soft female vocal singing over it. It sounds sad and soulful, like something you would hear at Sunday services.', 'author_id': 4, 'is_balanced_subset': False, 'is_audioset_eval': True}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('google/MusicCaps', split='train')\n",
    "for item in ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [00:00<00:00, 551387.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 443694.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [00:00<00:00, 621015.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 868/868 [00:00<00:00, 656565.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 732/732 [00:00<00:00, 650886.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 100262.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:00<00:00, 614042.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [00:00<00:00, 569596.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [00:00<00:00, 654139.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628/628 [00:00<00:00, 649574.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 601884.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1332/1332 [00:00<00:00, 708716.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 726/726 [00:00<00:00, 639853.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:00<00:00, 490953.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:00<00:00, 534507.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 377812.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [00:00<00:00, 571950.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [00:00<00:00, 489146.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 642/642 [00:00<00:00, 632396.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 / 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import torchaudio\n",
    "# input_path = \"../../FMA/002\"\n",
    "# output_path = \"../../FMA/002_wav\"\n",
    "# dir_list = os.listdir(input_path)\n",
    "# for item in dir_list:\n",
    "#     if item.endswith('.mp3'):\n",
    "#         file_path = os.path.join(input_path, item)\n",
    "#         wav, sr = torchaudio.load(file_path)\n",
    "#         output_file_path = os.path.join(output_path, item.replace('.mp3', '.wav'))\n",
    "#         torchaudio.save(output_file_path, wav, sr)\n",
    "#         print(f\"Converted {file_path} to {output_file_path}\")\n",
    "#     elif item.endswith('.txt'):\n",
    "#         # copy the text file to the output directory\n",
    "#         file_path = os.path.join(input_path, item)\n",
    "#         output_file_path = os.path.join(output_path, item)\n",
    "#         with open(file_path, 'r') as f:\n",
    "#             content = f.read()\n",
    "#         with open(output_file_path, 'w') as f:\n",
    "#             f.write(content)\n",
    "#         print(f\"Copied {file_path} to {output_file_path}\")\n",
    "        # python '/project/fyp24_ho3/tmtong/MuXiT/musicgen_trainer/run_multi.py' --dataset_path \"tmtong/MuXiT/FMA_data\" --model_id \"facebook/musicgen-stereo-melody\" --epochs 5 --batch_size 1 --devices \"1,2,3,4,5,6,7\"\n",
    "\n",
    "# nohup python '/project/fyp24_ho3/tmtong/MuXiT/musicgen_trainer/run_multi.py' --dataset_path \"tmtong/MuXiT/FMA_data\" --model_id \"facebook/musicgen-stereo-melody\" --epochs 5 --batch_size 1 --devices \"1,2,3,4,5,6,7\" > \"tmtong/MuXiT/training_log.out\" 2>&1 &\n",
    "\n",
    "# The above code converts mp3 files to wav files and copies the text files to a new directory.\n",
    "# now create a similar script but would parse through all the subdirectories in the input directory and convert all mp3 files to wav files and copy the text files to the output directory.\n",
    "import os\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "input_path = \"../../FMA/\"\n",
    "output_path = \"FMA_data/\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "dir_list = os.listdir(input_path)\n",
    "output_list = os.listdir(output_path)\n",
    "output_map = {k: False for k in output_list}\n",
    "dir_count = 0\n",
    "for item in dir_list:\n",
    "    sub_dir = os.path.join(input_path, item)\n",
    "    if os.path.isdir(sub_dir):\n",
    "        sub_dir_list = os.listdir(sub_dir)\n",
    "        for sub_item in tqdm(sub_dir_list):\n",
    "            try:\n",
    "                if sub_item.endswith('.mp3'):\n",
    "                    if sub_item[:-4]+'.wav' in output_map:\n",
    "                        continue\n",
    "                    file_path = os.path.join(sub_dir, sub_item)\n",
    "                    wav, sr = torchaudio.load(file_path)\n",
    "                    output_file_path = os.path.join(output_path, sub_item.replace('.mp3', '.wav'))\n",
    "                    torchaudio.save(output_file_path, wav, sr)\n",
    "                    # print(f\"Converted {file_path} to {output_file_path}\")\n",
    "                elif sub_item.endswith('.txt'):\n",
    "                    if sub_item in output_map:\n",
    "                        continue\n",
    "                    # copy the text file to the output directory\n",
    "                    file_path = os.path.join(sub_dir, sub_item)\n",
    "                    output_file_path = os.path.join(output_path, sub_item)\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        content = f.read()\n",
    "                    with open(output_file_path, 'w') as f:\n",
    "                        f.write(content)\n",
    "                    # print(f\"Copied {file_path} to {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                # remove the file if it is corrupted\n",
    "                if os.path.exists(file_path[:-4]+'.wav'):\n",
    "                    os.remove(file_path[:-4]+'.wav')\n",
    "                if os.path.exists(file_path[:-4]+'.txt'):\n",
    "                    os.remove(file_path[:-4]+'.txt')\n",
    "        dir_count += 1\n",
    "        print(f\"{dir_count} / {len(dir_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muxit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
